{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def load_data(path, dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32) \n",
    "    labels = encode_onehot(idx_features_labels[:, -1]) \n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test=load_data(path=\"./cora/\", dataset=\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    8,   14,  ..., 1389, 2344, 2707],\n",
      "                       [   0,    0,    0,  ..., 2707, 2707, 2707]]),\n",
      "       values=tensor([0.1667, 0.1667, 0.0500,  ..., 0.2000, 0.5000, 0.2500]),\n",
      "       size=(2708, 2708), nnz=13264, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "print(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3         4     5     6     7     8     9     ...  \\\n",
       "0      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4      0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...    ...   ...   ...   ...       ...   ...   ...   ...   ...   ...  ...   \n",
       "2703   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2704   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2705   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2706   0.0   0.0   0.0   0.0  0.052632   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2707   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "          1423  1424      1425  1426  1427  1428  1429  1430  1431  1432  \n",
       "0     0.000000   0.0  0.000000  0.05   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.000000   0.0  0.058824  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...        ...   ...       ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2703  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2704  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2705  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2706  0.052632   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2707  0.000000   0.0  0.000000  0.00   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2708 rows x 1433 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features=pd.DataFrame(features.numpy())\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser(\"./cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"w_{}\".format(ii) for ii in range(1433)]\n",
    "column_names =  feature_names + [\"subject\"]\n",
    "node_data = pd.read_csv(os.path.join(data_dir, \"cora.content\"), sep='\\t', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_0</th>\n",
       "      <th>w_1</th>\n",
       "      <th>w_2</th>\n",
       "      <th>w_3</th>\n",
       "      <th>w_4</th>\n",
       "      <th>w_5</th>\n",
       "      <th>w_6</th>\n",
       "      <th>w_7</th>\n",
       "      <th>w_8</th>\n",
       "      <th>w_9</th>\n",
       "      <th>...</th>\n",
       "      <th>w_1424</th>\n",
       "      <th>w_1425</th>\n",
       "      <th>w_1426</th>\n",
       "      <th>w_1427</th>\n",
       "      <th>w_1428</th>\n",
       "      <th>w_1429</th>\n",
       "      <th>w_1430</th>\n",
       "      <th>w_1431</th>\n",
       "      <th>w_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106418</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31353</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126029</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         w_0  w_1  w_2  w_3  w_4  w_5  w_6  w_7  w_8  w_9  ...  w_1424  \\\n",
       "31336      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1061127    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1106406    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "13195      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "37879      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1126012    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1107140    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1102850    0    0    0    1    0    0    0    0    0    0  ...       0   \n",
       "31349      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1106418    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1123188    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1128990    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "109323     0    0    1    0    0    0    0    0    0    0  ...       0   \n",
       "217139     0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "31353      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "32083      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1126029    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "1118017    0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "49482      0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "753265     0    0    0    0    0    0    0    0    0    0  ...       0   \n",
       "\n",
       "         w_1425  w_1426  w_1427  w_1428  w_1429  w_1430  w_1431  w_1432  \\\n",
       "31336         0       1       0       0       0       0       0       0   \n",
       "1061127       1       0       0       0       0       0       0       0   \n",
       "1106406       0       0       0       0       0       0       0       0   \n",
       "13195         0       0       0       0       0       0       0       0   \n",
       "37879         0       0       0       0       0       0       0       0   \n",
       "1126012       0       1       0       0       0       0       0       0   \n",
       "1107140       0       0       0       0       0       0       0       0   \n",
       "1102850       0       0       0       0       0       0       0       0   \n",
       "31349         0       0       0       0       0       0       0       0   \n",
       "1106418       0       0       0       0       0       0       0       0   \n",
       "1123188       0       0       0       0       0       0       0       0   \n",
       "1128990       0       1       0       0       0       0       0       0   \n",
       "109323        0       0       0       0       0       0       0       0   \n",
       "217139        0       0       0       0       0       0       0       0   \n",
       "31353         0       0       0       0       0       0       0       0   \n",
       "32083         0       0       0       0       0       0       0       0   \n",
       "1126029       0       0       0       0       0       0       0       0   \n",
       "1118017       0       0       0       0       0       0       0       0   \n",
       "49482         0       0       0       0       0       0       0       0   \n",
       "753265        0       0       0       0       0       0       0       0   \n",
       "\n",
       "                        subject  \n",
       "31336           Neural_Networks  \n",
       "1061127           Rule_Learning  \n",
       "1106406  Reinforcement_Learning  \n",
       "13195    Reinforcement_Learning  \n",
       "37879     Probabilistic_Methods  \n",
       "1126012   Probabilistic_Methods  \n",
       "1107140                  Theory  \n",
       "1102850         Neural_Networks  \n",
       "31349           Neural_Networks  \n",
       "1106418                  Theory  \n",
       "1123188         Neural_Networks  \n",
       "1128990      Genetic_Algorithms  \n",
       "109323    Probabilistic_Methods  \n",
       "217139               Case_Based  \n",
       "31353           Neural_Networks  \n",
       "32083           Neural_Networks  \n",
       "1126029  Reinforcement_Learning  \n",
       "1118017         Neural_Networks  \n",
       "49482           Neural_Networks  \n",
       "753265          Neural_Networks  \n",
       "\n",
       "[20 rows x 1434 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "..   ...\n",
       "135  135\n",
       "136  136\n",
       "137  137\n",
       "138  138\n",
       "139  139\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_train=pd.DataFrame(idx_train.numpy())\n",
    "df_idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0    200\n",
       "1    201\n",
       "2    202\n",
       "3    203\n",
       "4    204\n",
       "..   ...\n",
       "295  495\n",
       "296  496\n",
       "297  497\n",
       "298  498\n",
       "299  499\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_val=pd.DataFrame(idx_val.numpy())\n",
    "df_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     500\n",
       "1     501\n",
       "2     502\n",
       "3     503\n",
       "4     504\n",
       "..    ...\n",
       "995  1495\n",
       "996  1496\n",
       "997  1497\n",
       "998  1498\n",
       "999  1499\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idx_test=pd.DataFrame(idx_test.numpy())\n",
    "df_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCNN import NodeClassificationGCNN\n",
    "\n",
    "model = NodeClassificationGCNN(features.shape[1], 256, np.max(labels.detach().numpy())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out,label):\n",
    "    oneHotCodded = out.max(1)[1].type_as(label)\n",
    "    return oneHotCodded.eq(label).double().sum()/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0 ; accuracy: 0.1357142857142857; loss: 1.9466031789779663\n",
      "Validation epoch 0 ; accuracy: 0.29; loss: 1.9253942966461182\n",
      "Training epoch 1 ; accuracy: 0.4642857142857143; loss: 1.9068635702133179\n",
      "Validation epoch 1 ; accuracy: 0.4533333333333333; loss: 1.891020655632019\n",
      "Training epoch 2 ; accuracy: 0.6; loss: 1.8514143228530884\n",
      "Validation epoch 2 ; accuracy: 0.6133333333333333; loss: 1.8362115621566772\n",
      "Training epoch 3 ; accuracy: 0.7214285714285714; loss: 1.7754169702529907\n",
      "Validation epoch 3 ; accuracy: 0.6733333333333333; loss: 1.766838550567627\n",
      "Training epoch 4 ; accuracy: 0.7928571428571428; loss: 1.679965615272522\n",
      "Validation epoch 4 ; accuracy: 0.68; loss: 1.6899436712265015\n",
      "Training epoch 5 ; accuracy: 0.8214285714285714; loss: 1.5776610374450684\n",
      "Validation epoch 5 ; accuracy: 0.7; loss: 1.6084944009780884\n",
      "Training epoch 6 ; accuracy: 0.8357142857142857; loss: 1.4664320945739746\n",
      "Validation epoch 6 ; accuracy: 0.6966666666666667; loss: 1.5250842571258545\n",
      "Training epoch 7 ; accuracy: 0.8357142857142857; loss: 1.3545221090316772\n",
      "Validation epoch 7 ; accuracy: 0.71; loss: 1.440194010734558\n",
      "Training epoch 8 ; accuracy: 0.8428571428571429; loss: 1.2401537895202637\n",
      "Validation epoch 8 ; accuracy: 0.7166666666666667; loss: 1.3541821241378784\n",
      "Training epoch 9 ; accuracy: 0.85; loss: 1.1285251379013062\n",
      "Validation epoch 9 ; accuracy: 0.7166666666666667; loss: 1.2688838243484497\n",
      "Training epoch 10 ; accuracy: 0.8571428571428571; loss: 1.0143992900848389\n",
      "Validation epoch 10 ; accuracy: 0.7166666666666667; loss: 1.1868410110473633\n",
      "Training epoch 11 ; accuracy: 0.8642857142857143; loss: 0.9123435616493225\n",
      "Validation epoch 11 ; accuracy: 0.72; loss: 1.1100915670394897\n",
      "Training epoch 12 ; accuracy: 0.8714285714285714; loss: 0.8182726502418518\n",
      "Validation epoch 12 ; accuracy: 0.7166666666666667; loss: 1.0395591259002686\n",
      "Training epoch 13 ; accuracy: 0.8785714285714286; loss: 0.7336130738258362\n",
      "Validation epoch 13 ; accuracy: 0.7366666666666667; loss: 0.9757116436958313\n",
      "Training epoch 14 ; accuracy: 0.8785714285714286; loss: 0.6560333967208862\n",
      "Validation epoch 14 ; accuracy: 0.7433333333333333; loss: 0.9191535711288452\n",
      "Training epoch 15 ; accuracy: 0.8857142857142857; loss: 0.5860671997070312\n",
      "Validation epoch 15 ; accuracy: 0.75; loss: 0.8703805804252625\n",
      "Training epoch 16 ; accuracy: 0.8785714285714286; loss: 0.528242290019989\n",
      "Validation epoch 16 ; accuracy: 0.7566666666666667; loss: 0.8293020129203796\n",
      "Training epoch 17 ; accuracy: 0.8857142857142857; loss: 0.4779633581638336\n",
      "Validation epoch 17 ; accuracy: 0.7666666666666667; loss: 0.7954062819480896\n",
      "Training epoch 18 ; accuracy: 0.8928571428571429; loss: 0.43662968277931213\n",
      "Validation epoch 18 ; accuracy: 0.7666666666666667; loss: 0.767907440662384\n",
      "Training epoch 19 ; accuracy: 0.8928571428571429; loss: 0.40468159317970276\n",
      "Validation epoch 19 ; accuracy: 0.76; loss: 0.7458264231681824\n",
      "Training epoch 20 ; accuracy: 0.8928571428571429; loss: 0.3689638376235962\n",
      "Validation epoch 20 ; accuracy: 0.76; loss: 0.728938639163971\n",
      "Training epoch 21 ; accuracy: 0.8928571428571429; loss: 0.3415068984031677\n",
      "Validation epoch 21 ; accuracy: 0.77; loss: 0.7166226506233215\n",
      "Training epoch 22 ; accuracy: 0.8928571428571429; loss: 0.32104790210723877\n",
      "Validation epoch 22 ; accuracy: 0.7666666666666667; loss: 0.708196759223938\n",
      "Training epoch 23 ; accuracy: 0.8928571428571429; loss: 0.2988361120223999\n",
      "Validation epoch 23 ; accuracy: 0.7666666666666667; loss: 0.7035388350486755\n",
      "Training epoch 24 ; accuracy: 0.8928571428571429; loss: 0.2791408598423004\n",
      "Validation epoch 24 ; accuracy: 0.76; loss: 0.7020038366317749\n",
      "Training epoch 25 ; accuracy: 0.9; loss: 0.2676270604133606\n",
      "Validation epoch 25 ; accuracy: 0.7633333333333333; loss: 0.7031270265579224\n",
      "Training epoch 26 ; accuracy: 0.9071428571428571; loss: 0.25239482522010803\n",
      "Validation epoch 26 ; accuracy: 0.7633333333333333; loss: 0.7066813707351685\n",
      "Training epoch 27 ; accuracy: 0.9071428571428571; loss: 0.2436012476682663\n",
      "Validation epoch 27 ; accuracy: 0.7633333333333333; loss: 0.7121261358261108\n",
      "Training epoch 28 ; accuracy: 0.9071428571428571; loss: 0.23288877308368683\n",
      "Validation epoch 28 ; accuracy: 0.76; loss: 0.7186304330825806\n",
      "Training epoch 29 ; accuracy: 0.9071428571428571; loss: 0.21852447092533112\n",
      "Validation epoch 29 ; accuracy: 0.76; loss: 0.7253616452217102\n",
      "Training epoch 30 ; accuracy: 0.9071428571428571; loss: 0.2137000560760498\n",
      "Validation epoch 30 ; accuracy: 0.76; loss: 0.7323865294456482\n",
      "Training epoch 31 ; accuracy: 0.9142857142857143; loss: 0.20774908363819122\n",
      "Validation epoch 31 ; accuracy: 0.7566666666666667; loss: 0.7389312982559204\n",
      "Training epoch 32 ; accuracy: 0.9142857142857143; loss: 0.2033553272485733\n",
      "Validation epoch 32 ; accuracy: 0.7633333333333333; loss: 0.74509596824646\n",
      "Training epoch 33 ; accuracy: 0.9142857142857143; loss: 0.19658207893371582\n",
      "Validation epoch 33 ; accuracy: 0.7633333333333333; loss: 0.7510948777198792\n",
      "Training epoch 34 ; accuracy: 0.9214285714285714; loss: 0.19182850420475006\n",
      "Validation epoch 34 ; accuracy: 0.7633333333333333; loss: 0.7561734914779663\n",
      "Training epoch 35 ; accuracy: 0.9142857142857143; loss: 0.1891479194164276\n",
      "Validation epoch 35 ; accuracy: 0.7666666666666667; loss: 0.7599456906318665\n",
      "Training epoch 36 ; accuracy: 0.9214285714285714; loss: 0.1857810765504837\n",
      "Validation epoch 36 ; accuracy: 0.7666666666666667; loss: 0.7633169293403625\n",
      "Training epoch 37 ; accuracy: 0.9214285714285714; loss: 0.18231946229934692\n",
      "Validation epoch 37 ; accuracy: 0.77; loss: 0.7667425274848938\n",
      "Training epoch 38 ; accuracy: 0.9214285714285714; loss: 0.18038757145404816\n",
      "Validation epoch 38 ; accuracy: 0.7733333333333333; loss: 0.7697218060493469\n",
      "Training epoch 39 ; accuracy: 0.9214285714285714; loss: 0.17784762382507324\n",
      "Validation epoch 39 ; accuracy: 0.7733333333333333; loss: 0.7733469009399414\n",
      "Training epoch 40 ; accuracy: 0.9214285714285714; loss: 0.17480820417404175\n",
      "Validation epoch 40 ; accuracy: 0.7733333333333333; loss: 0.7772438526153564\n",
      "Training epoch 41 ; accuracy: 0.9214285714285714; loss: 0.17219926416873932\n",
      "Validation epoch 41 ; accuracy: 0.7733333333333333; loss: 0.7814610004425049\n",
      "Training epoch 42 ; accuracy: 0.9214285714285714; loss: 0.17086094617843628\n",
      "Validation epoch 42 ; accuracy: 0.7766666666666666; loss: 0.7856776714324951\n",
      "Training epoch 43 ; accuracy: 0.9214285714285714; loss: 0.16920943558216095\n",
      "Validation epoch 43 ; accuracy: 0.78; loss: 0.7901852130889893\n",
      "Training epoch 44 ; accuracy: 0.9214285714285714; loss: 0.16827671229839325\n",
      "Validation epoch 44 ; accuracy: 0.78; loss: 0.7949399948120117\n",
      "Training epoch 45 ; accuracy: 0.9214285714285714; loss: 0.16662481427192688\n",
      "Validation epoch 45 ; accuracy: 0.7766666666666666; loss: 0.8001210689544678\n",
      "Training epoch 46 ; accuracy: 0.9214285714285714; loss: 0.1660691648721695\n",
      "Validation epoch 46 ; accuracy: 0.78; loss: 0.8055763244628906\n",
      "Training epoch 47 ; accuracy: 0.9214285714285714; loss: 0.16548477113246918\n",
      "Validation epoch 47 ; accuracy: 0.78; loss: 0.8114067912101746\n",
      "Training epoch 48 ; accuracy: 0.9214285714285714; loss: 0.16461659967899323\n",
      "Validation epoch 48 ; accuracy: 0.78; loss: 0.8172538876533508\n",
      "Training epoch 49 ; accuracy: 0.9214285714285714; loss: 0.16337522864341736\n",
      "Validation epoch 49 ; accuracy: 0.78; loss: 0.8230984210968018\n",
      "Training epoch 50 ; accuracy: 0.9214285714285714; loss: 0.16297005116939545\n",
      "Validation epoch 50 ; accuracy: 0.78; loss: 0.8284516930580139\n",
      "Training epoch 51 ; accuracy: 0.9214285714285714; loss: 0.16204620897769928\n",
      "Validation epoch 51 ; accuracy: 0.78; loss: 0.8335934281349182\n",
      "Training epoch 52 ; accuracy: 0.9214285714285714; loss: 0.16301055252552032\n",
      "Validation epoch 52 ; accuracy: 0.78; loss: 0.8380488157272339\n",
      "Training epoch 53 ; accuracy: 0.9214285714285714; loss: 0.16139249503612518\n",
      "Validation epoch 53 ; accuracy: 0.7766666666666666; loss: 0.842196524143219\n",
      "Training epoch 54 ; accuracy: 0.9214285714285714; loss: 0.16136276721954346\n",
      "Validation epoch 54 ; accuracy: 0.7766666666666666; loss: 0.8460973501205444\n",
      "Training epoch 55 ; accuracy: 0.9214285714285714; loss: 0.16072802245616913\n",
      "Validation epoch 55 ; accuracy: 0.7766666666666666; loss: 0.8493860363960266\n",
      "Training epoch 56 ; accuracy: 0.9214285714285714; loss: 0.16007225215435028\n",
      "Validation epoch 56 ; accuracy: 0.7733333333333333; loss: 0.8523574471473694\n",
      "Training epoch 57 ; accuracy: 0.9214285714285714; loss: 0.15966898202896118\n",
      "Validation epoch 57 ; accuracy: 0.7733333333333333; loss: 0.8553635478019714\n",
      "Training epoch 58 ; accuracy: 0.9214285714285714; loss: 0.1597093790769577\n",
      "Validation epoch 58 ; accuracy: 0.7733333333333333; loss: 0.8581170439720154\n",
      "Training epoch 59 ; accuracy: 0.9214285714285714; loss: 0.15875189006328583\n",
      "Validation epoch 59 ; accuracy: 0.7733333333333333; loss: 0.8610216379165649\n",
      "Training epoch 60 ; accuracy: 0.9214285714285714; loss: 0.15916550159454346\n",
      "Validation epoch 60 ; accuracy: 0.7733333333333333; loss: 0.863900363445282\n",
      "Training epoch 61 ; accuracy: 0.9214285714285714; loss: 0.15857166051864624\n",
      "Validation epoch 61 ; accuracy: 0.7733333333333333; loss: 0.8667199611663818\n",
      "Training epoch 62 ; accuracy: 0.9214285714285714; loss: 0.1587221920490265\n",
      "Validation epoch 62 ; accuracy: 0.7733333333333333; loss: 0.8697086572647095\n",
      "Training epoch 63 ; accuracy: 0.9214285714285714; loss: 0.1585734337568283\n",
      "Validation epoch 63 ; accuracy: 0.7666666666666667; loss: 0.8729265332221985\n",
      "Training epoch 64 ; accuracy: 0.9214285714285714; loss: 0.15856225788593292\n",
      "Validation epoch 64 ; accuracy: 0.7666666666666667; loss: 0.8763247728347778\n",
      "Training epoch 65 ; accuracy: 0.9214285714285714; loss: 0.15788477659225464\n",
      "Validation epoch 65 ; accuracy: 0.7666666666666667; loss: 0.8795070648193359\n",
      "Training epoch 66 ; accuracy: 0.9214285714285714; loss: 0.15767772495746613\n",
      "Validation epoch 66 ; accuracy: 0.7666666666666667; loss: 0.8821548223495483\n",
      "Training epoch 67 ; accuracy: 0.9214285714285714; loss: 0.15774613618850708\n",
      "Validation epoch 67 ; accuracy: 0.7666666666666667; loss: 0.8847366571426392\n",
      "Training epoch 68 ; accuracy: 0.9214285714285714; loss: 0.15720418095588684\n",
      "Validation epoch 68 ; accuracy: 0.7666666666666667; loss: 0.8870123028755188\n",
      "Training epoch 69 ; accuracy: 0.9214285714285714; loss: 0.15715238451957703\n",
      "Validation epoch 69 ; accuracy: 0.7666666666666667; loss: 0.8890507817268372\n",
      "Training epoch 70 ; accuracy: 0.9214285714285714; loss: 0.15700504183769226\n",
      "Validation epoch 70 ; accuracy: 0.7666666666666667; loss: 0.8911186456680298\n",
      "Training epoch 71 ; accuracy: 0.9214285714285714; loss: 0.1572379320859909\n",
      "Validation epoch 71 ; accuracy: 0.7666666666666667; loss: 0.8929846286773682\n",
      "Training epoch 72 ; accuracy: 0.9214285714285714; loss: 0.15680117905139923\n",
      "Validation epoch 72 ; accuracy: 0.7666666666666667; loss: 0.8945592045783997\n",
      "Training epoch 73 ; accuracy: 0.9214285714285714; loss: 0.15699626505374908\n",
      "Validation epoch 73 ; accuracy: 0.7666666666666667; loss: 0.8961469531059265\n",
      "Training epoch 74 ; accuracy: 0.9214285714285714; loss: 0.1565524935722351\n",
      "Validation epoch 74 ; accuracy: 0.7666666666666667; loss: 0.8977853655815125\n",
      "Training epoch 75 ; accuracy: 0.9214285714285714; loss: 0.1565646231174469\n",
      "Validation epoch 75 ; accuracy: 0.7666666666666667; loss: 0.8990688920021057\n",
      "Training epoch 76 ; accuracy: 0.9214285714285714; loss: 0.1568329930305481\n",
      "Validation epoch 76 ; accuracy: 0.7666666666666667; loss: 0.900221586227417\n",
      "Training epoch 77 ; accuracy: 0.9214285714285714; loss: 0.15610940754413605\n",
      "Validation epoch 77 ; accuracy: 0.7666666666666667; loss: 0.9009432196617126\n",
      "Training epoch 78 ; accuracy: 0.9214285714285714; loss: 0.15643776953220367\n",
      "Validation epoch 78 ; accuracy: 0.77; loss: 0.9015844464302063\n",
      "Training epoch 79 ; accuracy: 0.9214285714285714; loss: 0.15689173340797424\n",
      "Validation epoch 79 ; accuracy: 0.77; loss: 0.9025409817695618\n",
      "Training epoch 80 ; accuracy: 0.9214285714285714; loss: 0.15604612231254578\n",
      "Validation epoch 80 ; accuracy: 0.77; loss: 0.9034249782562256\n",
      "Training epoch 81 ; accuracy: 0.9214285714285714; loss: 0.1563478410243988\n",
      "Validation epoch 81 ; accuracy: 0.77; loss: 0.9043504595756531\n",
      "Training epoch 82 ; accuracy: 0.9214285714285714; loss: 0.15632738173007965\n",
      "Validation epoch 82 ; accuracy: 0.77; loss: 0.9051169753074646\n",
      "Training epoch 83 ; accuracy: 0.9214285714285714; loss: 0.15599417686462402\n",
      "Validation epoch 83 ; accuracy: 0.77; loss: 0.9058828949928284\n",
      "Training epoch 84 ; accuracy: 0.9214285714285714; loss: 0.15610229969024658\n",
      "Validation epoch 84 ; accuracy: 0.77; loss: 0.906707763671875\n",
      "Training epoch 85 ; accuracy: 0.9214285714285714; loss: 0.15624386072158813\n",
      "Validation epoch 85 ; accuracy: 0.77; loss: 0.907522976398468\n",
      "Training epoch 86 ; accuracy: 0.9214285714285714; loss: 0.15588390827178955\n",
      "Validation epoch 86 ; accuracy: 0.77; loss: 0.9083990454673767\n",
      "Training epoch 87 ; accuracy: 0.9214285714285714; loss: 0.15576770901679993\n",
      "Validation epoch 87 ; accuracy: 0.77; loss: 0.909044086933136\n",
      "Training epoch 88 ; accuracy: 0.9214285714285714; loss: 0.1556333750486374\n",
      "Validation epoch 88 ; accuracy: 0.77; loss: 0.9096540212631226\n",
      "Training epoch 89 ; accuracy: 0.9214285714285714; loss: 0.15566790103912354\n",
      "Validation epoch 89 ; accuracy: 0.77; loss: 0.9104176759719849\n",
      "Training epoch 90 ; accuracy: 0.9214285714285714; loss: 0.15549789369106293\n",
      "Validation epoch 90 ; accuracy: 0.7666666666666667; loss: 0.9114453196525574\n",
      "Training epoch 91 ; accuracy: 0.9214285714285714; loss: 0.1557074785232544\n",
      "Validation epoch 91 ; accuracy: 0.7666666666666667; loss: 0.9124810695648193\n",
      "Training epoch 92 ; accuracy: 0.9214285714285714; loss: 0.15554924309253693\n",
      "Validation epoch 92 ; accuracy: 0.7666666666666667; loss: 0.9135746359825134\n",
      "Training epoch 93 ; accuracy: 0.9214285714285714; loss: 0.15540054440498352\n",
      "Validation epoch 93 ; accuracy: 0.7666666666666667; loss: 0.9145654439926147\n",
      "Training epoch 94 ; accuracy: 0.9214285714285714; loss: 0.15543073415756226\n",
      "Validation epoch 94 ; accuracy: 0.7666666666666667; loss: 0.9154381155967712\n",
      "Training epoch 95 ; accuracy: 0.9214285714285714; loss: 0.1554306149482727\n",
      "Validation epoch 95 ; accuracy: 0.7666666666666667; loss: 0.9164637327194214\n",
      "Training epoch 96 ; accuracy: 0.9214285714285714; loss: 0.15526065230369568\n",
      "Validation epoch 96 ; accuracy: 0.7666666666666667; loss: 0.9175815582275391\n",
      "Training epoch 97 ; accuracy: 0.9214285714285714; loss: 0.15533991158008575\n",
      "Validation epoch 97 ; accuracy: 0.7666666666666667; loss: 0.9186225533485413\n",
      "Training epoch 98 ; accuracy: 0.9214285714285714; loss: 0.1551923304796219\n",
      "Validation epoch 98 ; accuracy: 0.7666666666666667; loss: 0.9191969037055969\n",
      "Training epoch 99 ; accuracy: 0.9214285714285714; loss: 0.15510006248950958\n",
      "Validation epoch 99 ; accuracy: 0.7666666666666667; loss: 0.9198479056358337\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "epochs=100\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "train_accuracy=[]\n",
    "val_accuracy=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_labels=labels[idx_train]\n",
    "    val_labels=labels[idx_val]\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    train_loss=F.nll_loss(output[idx_train],train_labels)\n",
    "    train_losses.append(train_loss)\n",
    "    t_a=accuracy(output[idx_train],train_labels)\n",
    "    train_accuracy.append(t_a)\n",
    "    print(f\"Training epoch {epoch} ; accuracy: {accuracy(output[idx_train],train_labels)}; loss: {train_loss.item()}\")\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    val_loss=F.nll_loss(output[idx_val],val_labels)\n",
    "    val_losses.append(val_loss)\n",
    "    v_a=accuracy(output[idx_val],val_labels)\n",
    "    val_accuracy.append(v_a)\n",
    "    print(f\"Validation epoch {epoch} ; accuracy: {accuracy(output[idx_val],val_labels)}; loss: {val_loss.item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses_float=[float(train_loss.cpu().detach().numpy()) for train_loss in train_losses]\n",
    "train_loss_indices=[i for i, l in enumerate(train_losses_float)]\n",
    "plt=sns.lineplot(train_loss_indices,train_losses_float)\n",
    "val_losses_float=[float(val_loss.cpu().detach().numpy()) for val_loss in val_losses]\n",
    "val_loss_indices=[i for i, l in enumerate(val_losses_float)]\n",
    "plt=sns.lineplot(val_loss_indices,val_losses_float,color='r')\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_a = t_a.cpu().detach().numpy()\n",
    "v_a = v_a.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/home/kangjunekoo/anaconda3/envs/pytorch/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy_float=[float(t_a.cpu().detach().numpy()) for t_a in train_accuracy]\n",
    "t_a_indices=[i for i, l in enumerate(train_accuracy_float)]\n",
    "plt=sns.lineplot(t_a_indices,train_accuracy_float,color='green')\n",
    "\n",
    "val_accuracy_float=[float(v_a.cpu().detach().numpy()) for v_a in val_accuracy]\n",
    "v_a_indices=[i for i, l in enumerate(val_accuracy_float)]\n",
    "plt=sns.lineplot(v_a_indices,val_accuracy_float,color='black')\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ; accuracy: 0.669; loss: 0.9876585006713867\n"
     ]
    }
   ],
   "source": [
    "test_losses=[]\n",
    "model.eval()\n",
    "test_labels=labels[idx_test]\n",
    "output = model(features, adj)\n",
    "loss=F.nll_loss(output[idx_test],test_labels)\n",
    "test_losses.append(loss)\n",
    "print(f\"Test set ; accuracy: {accuracy(output[idx_test],test_labels)}; loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sample = 500\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(model(features, adj).shape)\n",
    "pred = model(features, adj)\n",
    "sns.barplot(x=np.array(range(7)), y=pred[sample].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idx_test=output[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-0.170443</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.651942</td>\n",
       "      <td>-3.611710</td>\n",
       "      <td>-3.651942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.826761</td>\n",
       "      <td>-4.853640</td>\n",
       "      <td>-3.768618</td>\n",
       "      <td>-4.721383</td>\n",
       "      <td>-0.067527</td>\n",
       "      <td>-4.853640</td>\n",
       "      <td>-4.635790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-0.020207</td>\n",
       "      <td>-7.502378</td>\n",
       "      <td>-4.087018</td>\n",
       "      <td>-6.900223</td>\n",
       "      <td>-7.502378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.303761</td>\n",
       "      <td>-5.376230</td>\n",
       "      <td>-0.026949</td>\n",
       "      <td>-5.499911</td>\n",
       "      <td>-5.353931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.788297</td>\n",
       "      <td>-4.842309</td>\n",
       "      <td>-0.126655</td>\n",
       "      <td>-4.842309</td>\n",
       "      <td>-3.616222</td>\n",
       "      <td>-2.847855</td>\n",
       "      <td>-4.604618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.014552</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-1.524173</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-2.123931</td>\n",
       "      <td>-1.768575</td>\n",
       "      <td>-2.123931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-8.949731</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-9.862147</td>\n",
       "      <td>-10.944406</td>\n",
       "      <td>-0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-5.510885</td>\n",
       "      <td>-6.888665</td>\n",
       "      <td>-5.485894</td>\n",
       "      <td>-6.888665</td>\n",
       "      <td>-6.215913</td>\n",
       "      <td>-6.559607</td>\n",
       "      <td>-0.013734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.251792</td>\n",
       "      <td>-3.885541</td>\n",
       "      <td>-2.580560</td>\n",
       "      <td>-3.473157</td>\n",
       "      <td>-3.574414</td>\n",
       "      <td>-3.669913</td>\n",
       "      <td>-0.628839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-7.454676</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-8.172600</td>\n",
       "      <td>-0.004029</td>\n",
       "      <td>-6.188050</td>\n",
       "      <td>-7.520314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5         6\n",
       "0   -3.651942  -3.651942  -0.170443  -3.651942 -3.651942  -3.611710 -3.651942\n",
       "1   -4.826761  -4.853640  -3.768618  -4.721383 -0.067527  -4.853640 -4.635790\n",
       "2   -7.502378  -7.502378  -0.020207  -7.502378 -4.087018  -6.900223 -7.502378\n",
       "3   -5.499911  -5.499911  -5.303761  -5.376230 -0.026949  -5.499911 -5.353931\n",
       "4   -4.788297  -4.842309  -0.126655  -4.842309 -3.616222  -2.847855 -4.604618\n",
       "..        ...        ...        ...        ...       ...        ...       ...\n",
       "995 -2.014552  -2.123931  -1.524173  -2.123931 -2.123931  -1.768575 -2.123931\n",
       "996 -8.949731 -10.944406 -10.944406 -10.944406 -9.862147 -10.944406 -0.000253\n",
       "997 -5.510885  -6.888665  -5.485894  -6.888665 -6.215913  -6.559607 -0.013734\n",
       "998 -1.251792  -3.885541  -2.580560  -3.473157 -3.574414  -3.669913 -0.628839\n",
       "999 -7.454676  -8.172600  -8.172600  -8.172600 -0.004029  -6.188050 -7.520314\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_idx_test=pd.DataFrame(output_idx_test.detach().numpy())\n",
    "df_output_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
       "0    2    4    2    4    4    4    2    5    5    0  ...    4    5    5    4   \n",
       "\n",
       "   994  995  996  997  998  999  \n",
       "0    4    1    6    6    6    4  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_labels=pd.DataFrame(test_labels.numpy())\n",
    "print(type(df_test_labels))\n",
    "df_test_labels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "366252978e52bb2df929d3934aeb3ff29dfa67e45e575a59a0b0194f7beef5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
